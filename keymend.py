import os
import json
import requests
import pandas as pd
from dotenv import load_dotenv
from pytrends.request import TrendReq

# =========================================================
# 1. ENV ë¡œë“œ
# =========================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
load_dotenv(os.path.join(BASE_DIR, "naver.env"))

NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
    raise EnvironmentError("NAVER_CLIENT_ID ë˜ëŠ” NAVER_CLIENT_SECRETì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# =========================================================
# 2. ë„¤ì´ë²„ ë°ì´í„°ë©
# =========================================================
def fetch_naver_trend(keywords, start_date, end_date):
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
        "Content-Type": "application/json"
    }

    rows = []

    for kw in keywords:
        payload = {
            "startDate": start_date,
            "endDate": end_date,
            "timeUnit": "month",
            "keywordGroups": [
                {
                    "groupName": kw,
                    "keywords": [kw]
                }
            ]
        }

        res = requests.post(url, headers=headers, data=json.dumps(payload))
        res.raise_for_status()

        data = res.json()["results"][0]["data"]

        for d in data:
            rows.append({
                "keyword": kw,
                "date": d["period"],
                "ratio": d["ratio"]
            })

    return pd.DataFrame(rows)

# =========================================================
# 3. ìƒìŠ¹ë¥  ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì²œ
# =========================================================
def recommend_keywords(df, top_n=5):
    recommendations = []

    for kw, g in df.groupby("keyword"):
        g = g.sort_values("date")

        if len(g) < 3:
            continue

        recent = g.iloc[-1]["ratio"]
        prev_avg = g.iloc[-3:-1]["ratio"].mean()

        growth = ((recent - prev_avg) / prev_avg) * 100 if prev_avg > 0 else 0

        recommendations.append({
            "keyword": kw,
            "latest_ratio": round(recent, 2),
            "growth_rate(%)": round(growth, 2)
        })

    rec_df = pd.DataFrame(recommendations)
    return rec_df.sort_values("growth_rate(%)", ascending=False).head(top_n)

# =========================================================
# 4. ì‹¤í–‰ë¶€
# =========================================================
if __name__ == "__main__":
    # ğŸ”¹ í‚¤ì›Œë“œ í›„ë³´ í’€ (ì—¬ê¸°ë§Œ ê³„ì† ëŠ˜ë¦¬ë©´ ë©ë‹ˆë‹¤)
    keyword_pool = [
        "ì¸ê³µì§€ëŠ¥", "ChatGPT", "ìƒì„±í˜• AI", "AI íˆ¬ì", "AI ê´€ë ¨ì£¼",
        "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§", "AI ìœ¤ë¦¬", "AI ê·œì œ", "ì˜¤í”ˆAI", "LLM"
    ]

    df = fetch_naver_trend(
        keywords=keyword_pool,
        start_date="2024-01-01",
        end_date="2024-12-31"
    )

    ì¶”ì²œ = recommend_keywords(df, top_n=5)

    print("\nğŸ”¥ ì´ë²ˆ ì£¼ ë¸”ë¡œê·¸ ì¶”ì²œ í‚¤ì›Œë“œ TOP 5")
    print(ì¶”ì²œ)

    ì¶”ì²œ.to_csv("weekly_keyword_recommendation.csv", index=False)